{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# in file .env write a line \n",
    "# EDEN_API=...\n",
    "\n",
    "load_dotenv(Path()/\"env/.env\")\n",
    "api_key = os.getenv(\"EDEN_API\")\n",
    "\n",
    "# print to check that it works to access the API key, but\n",
    "# never commit a printed API key\n",
    "#print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detail': 'Invalid Api Key'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "url = \"https://api.edenai.run/v2/text/chat\"\n",
    "payload = {\n",
    "    \"providers\": \"openai\",\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"text\": \"Hello i need your help ! \",\n",
    "    \"chatbot_global_action\": \"Act as an assistant\",\n",
    "    \"previous_history\": [],\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 150,\n",
    "    \"fallback_providers\": \"perplexityai\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "result = json.loads(response.text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 21\u001b[0m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mberätta ett nördigt skämt om programmerare\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mchat\u001b[1;34m(prompt, max_tokens, provider, model, temperature)\u001b[0m\n\u001b[0;32m     16\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, json\u001b[38;5;241m=\u001b[39mpayload, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m     18\u001b[0m result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenai\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'openai'"
     ]
    }
   ],
   "source": [
    "def chat(prompt, max_tokens=300, provider=\"openai\", model=\"gpt-3.5-turbo-0125\", temperature=0.5):\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "    url = \"https://api.edenai.run/v2/text/chat\"\n",
    "    payload = {\n",
    "        \"providers\": provider,\n",
    "        \"model\": model,\n",
    "        \"text\": prompt,\n",
    "        \"chatbot_global_action\": \"Act as an assistant\", # try change this\n",
    "        \"previous_history\": [],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"fallback_providers\": \"perplexityai\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "    result = json.loads(response.text)\n",
    "    return result[\"openai\"][\"generated_text\"]\n",
    "\n",
    "chat(\"berätta ett nördigt skämt om programmerare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path().absolute().parents()\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path / \"programmering-med-ai-kompetens.txt\", \"r\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_opa_gpt35_turbo = chat(\n",
    "f\"\"\" kan du sammanfatta den här texten i max ett stycke. Här är texten\n",
    "\n",
    "{raw_text}\n",
    "\n",
    "\"\"\", model=\"gpt-3.5-turbo\")\n",
    "\n",
    "summary_opa_gpt35_turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_opa = chat(\n",
    "f\"\"\" kan du sammanfatta den här texten i max ett stycke. Här är texten\n",
    "'''\n",
    "{raw_text}\n",
    "'''\"\n",
    "\n",
    "Formatera svaret likt följande exempel\n",
    "'''\n",
    "\n",
    "Texten beskriver AI och utbildning ...\n",
    "\n",
    "Några viktiga delar är:\n",
    "- punkt 1\n",
    "- punkt 2\n",
    "- ...\n",
    "\n",
    "\"\"\", model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_opa = chat(\n",
    "f\"\"\"{raw_text}'''\n",
    "\n",
    "\n",
    "Vad får man lära sig i dden här utbildningen? Beskriv i puktformat. Ge mig tre ppunkter på de viktigaste delarna\n",
    "'''\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(learn_opa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_opa = chat(\n",
    "f\"\"\"'''{raw_text}'''\n",
    "\n",
    "\n",
    "Vilka ska man kontakta om man är intresseras av utbildningen?\n",
    "\n",
    "Formatera i en lista på kontakter\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(contacts_opa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_markdown = chat(\n",
    "f\"\"\"'''{raw_text}'''\n",
    "\n",
    "\n",
    "Vilka ska man kontakta om man är intresseras av utbildningen?\n",
    "\n",
    "Formatera i en markdowntabell med kolumnerana: Kontakt, Mail, Telefon\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(contacts_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that some postprocessing could be good\n",
    "print(contacts_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_df = chat(\n",
    "f\"\"\"'''{raw_text}'''\n",
    "\n",
    "\n",
    "Vilka ska man kontakta om man är intresseras av utbildningen?\n",
    "\n",
    "Formatera i en dataframe med kolumnerana: Kontakt, Mail, Telefon\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "contacts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contacts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscraper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FaqScraper\n\u001b[0;32m      3\u001b[0m faq \u001b[38;5;241m=\u001b[39m FaqScraper()\n\u001b[0;32m      4\u001b[0m faq\n",
      "File \u001b[1;32mc:\\Users\\Sandra\\Documents\\Github\\AI-Sandra-Andersson-OPA23\\code_alongs\\utils\\scraper.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNBILinkScraper\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "from utils.scraper import FaqScraper\n",
    "\n",
    "faq = FaqScraper()\n",
    "faq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_list = faq.faq\n",
    "faq_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"|n|n\".join(faq_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [text for textin faq_list if \"?\" in text]\n",
    "\n",
    "questions[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
